# Welcome to MMTrustEval
![framework](framework.png)

* MMTrustEval (MMTE) is a toolbox developed for benchmarking trustworthiness of Multimodal Large Language Models (MLLMs). ([paper](https://arxiv.org/pdf/2406.07057))
* It provides a universal and scalable infrastructure for evaluating MLLM trustworthiness and facilitating future research.
* Different MLLMs are integrated into a unified interface to conduct standardized inference.
* Tasks are modularized by separting data, inference, and evaluation metrics to encourage tool reuse and easy updates for new tasks to be added.